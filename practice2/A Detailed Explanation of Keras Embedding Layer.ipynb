{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 커널 : A Detailed Explanation of Keras Embedding Layer\n",
    "- https://www.kaggle.com/rajmehra03/a-detailed-explanation-of-keras-embedding-layer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#configure\n",
    "#sets matplotlib to incline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#nltk\n",
    "import nltk\n",
    "\n",
    "#stop-words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "#tokenizing\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "\n",
    "#keras\n",
    "import keras\n",
    "from keras.preprocessing.text import one_hot, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Flatten ,Embedding,Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text_1=\"bitty bought a bir of butter\"\n",
    "sample_text_2=\"but the bit of butter was a bit bitter\"\n",
    "sample_text_3=\"so she bought some better butter to make the bitter butter better\"\n",
    "\n",
    "corp=[sample_text_1,sample_text_2,sample_text_3]\n",
    "no_docs=len(corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoding for document 1  is :  [34, 9, 6, 24, 12, 8]\n",
      "The encoding for document 2  is :  [40, 48, 42, 12, 8, 18, 6, 42, 11]\n",
      "The encoding for document 3  is :  [3, 28, 9, 24, 9, 8, 46, 33, 48, 11, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "vocab_size=50\n",
    "encod_corp=[]\n",
    "for i,doc in enumerate(corp):\n",
    "    encod_corp.append(one_hot(doc,50))\n",
    "    print(\"The encoding for document\",i+1,\" is : \",one_hot(doc,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of words in any document is :  12\n"
     ]
    }
   ],
   "source": [
    "# length of maximum document. will be nedded whenever create embedding for the words\n",
    "maxlen=-1\n",
    "for doc in corp:\n",
    "    tokens=nltk.word_tokenize(doc)\n",
    "    if(maxlen<len(tokens)):\n",
    "        maxlen=len(tokens)\n",
    "print(\"The maximum number of words in any document is : \",maxlen)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of padded documents:  3\n"
     ]
    }
   ],
   "source": [
    "# now to create embeddings all of our docs need to be of same length. hence we can pad the docs with zeros.\n",
    "pad_corp=pad_sequences(encod_corp,maxlen=maxlen,padding='post',value=0.0)\n",
    "print(\"No of padded documents: \",len(pad_corp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The padded encoding for document 1  is :  [34  9  6 24 12  8  0  0  0  0  0  0]\n",
      "The padded encoding for document 2  is :  [40 48 42 12  8 18  6 42 11  0  0  0]\n",
      "The padded encoding for document 3  is :  [ 3 28  9 24  9  8 46 33 48 11  8  9]\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(pad_corp):\n",
    "    print(\"The padded encoding for document\",i+1,\" is : \",doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying the input shape\n",
    "input=Input(shape=(no_docs,maxlen),dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "shape of input.\n",
    "each document has 12 element or words which is the value of our maxlen varialble.\n",
    "\n",
    "'''\n",
    "word_input=Input(shape=(maxlen,),dtype='float64')\n",
    "\n",
    "#creating the embedding\n",
    "word_embedding=Embedding(input_dim=vocab_size,output_dim=8,input_length=maxlen)(word_input)\n",
    "\n",
    "word_vec=Flatten()(word_embedding) # flatten\n",
    "embed_model =Model([word_input],word_vec) # combining all into a Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3),loss='binary_crossentropy',metrics=['acc']) \n",
    "# compiling the model. parameters can be tuned as always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"embedding_1/embedding_lookup/Identity_1:0\", shape=(None, 12, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(type(word_embedding))\n",
    "print(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 12, 8)             400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 96)                0         \n",
      "=================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(embed_model.summary()) #summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=embed_model.predict(pad_corp) #finally getting the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings :  (3, 96)\n",
      "[[ 0.03011117 -0.02670218 -0.00847875  0.034897   -0.01051865 -0.02711916\n",
      "  -0.02487536 -0.02674422 -0.00881178 -0.0483201  -0.00987961  0.02456332\n",
      "   0.00283928 -0.01529993  0.01785861 -0.01242632 -0.03739148 -0.02144562\n",
      "   0.04590155 -0.02630723 -0.0317054  -0.04067265 -0.02565771  0.0188408\n",
      "   0.01338479  0.01484675 -0.00882455 -0.00779973  0.0283351  -0.04327079\n",
      "   0.02083454 -0.04233762 -0.03554603  0.04314442 -0.03227742 -0.0430434\n",
      "  -0.01460426 -0.03224637 -0.02712467 -0.03528814 -0.04699592 -0.02463116\n",
      "  -0.00887086 -0.04108449 -0.01765037 -0.03592086 -0.02967109  0.00558911\n",
      "  -0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874  0.03153331\n",
      "  -0.00326921 -0.01445078 -0.0462851   0.00482037 -0.01747657 -0.00098497\n",
      "   0.03795874  0.03153331 -0.00326921 -0.01445078 -0.0462851   0.00482037\n",
      "  -0.01747657 -0.00098497  0.03795874  0.03153331 -0.00326921 -0.01445078\n",
      "  -0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874  0.03153331\n",
      "  -0.00326921 -0.01445078 -0.0462851   0.00482037 -0.01747657 -0.00098497\n",
      "   0.03795874  0.03153331 -0.00326921 -0.01445078 -0.0462851   0.00482037\n",
      "  -0.01747657 -0.00098497  0.03795874  0.03153331 -0.00326921 -0.01445078]\n",
      " [ 0.04607674 -0.00758297 -0.03569062  0.01863006 -0.04490864 -0.04510683\n",
      "   0.01303491  0.02913488  0.02996481  0.00297766  0.03417213 -0.02279012\n",
      "  -0.01034534  0.02630845 -0.03460188  0.00932224 -0.01300643  0.01481131\n",
      "  -0.03093816  0.00416549 -0.04258502  0.03763345 -0.03530914  0.00040434\n",
      "  -0.03554603  0.04314442 -0.03227742 -0.0430434  -0.01460426 -0.03224637\n",
      "  -0.02712467 -0.03528814 -0.04699592 -0.02463116 -0.00887086 -0.04108449\n",
      "  -0.01765037 -0.03592086 -0.02967109  0.00558911 -0.0336052   0.04775343\n",
      "  -0.04578439  0.0457306   0.00208535 -0.04167062 -0.02230759  0.04546758\n",
      "  -0.03739148 -0.02144562  0.04590155 -0.02630723 -0.0317054  -0.04067265\n",
      "  -0.02565771  0.0188408  -0.01300643  0.01481131 -0.03093816  0.00416549\n",
      "  -0.04258502  0.03763345 -0.03530914  0.00040434 -0.04352104 -0.02126801\n",
      "   0.03686359 -0.02912866 -0.01059956  0.00259133  0.00324165 -0.04615122\n",
      "  -0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874  0.03153331\n",
      "  -0.00326921 -0.01445078 -0.0462851   0.00482037 -0.01747657 -0.00098497\n",
      "   0.03795874  0.03153331 -0.00326921 -0.01445078 -0.0462851   0.00482037\n",
      "  -0.01747657 -0.00098497  0.03795874  0.03153331 -0.00326921 -0.01445078]\n",
      " [-0.04767499  0.01561514  0.00049329  0.02191934 -0.03796053  0.04406155\n",
      "   0.03259062 -0.04780463 -0.01540776  0.02702776  0.02418702 -0.0087474\n",
      "   0.00180035  0.01054322 -0.0187981   0.01683738 -0.00881178 -0.0483201\n",
      "  -0.00987961  0.02456332  0.00283928 -0.01529993  0.01785861 -0.01242632\n",
      "   0.01338479  0.01484675 -0.00882455 -0.00779973  0.0283351  -0.04327079\n",
      "   0.02083454 -0.04233762 -0.00881178 -0.0483201  -0.00987961  0.02456332\n",
      "   0.00283928 -0.01529993  0.01785861 -0.01242632 -0.04699592 -0.02463116\n",
      "  -0.00887086 -0.04108449 -0.01765037 -0.03592086 -0.02967109  0.00558911\n",
      "   0.04813459 -0.00118749  0.04338625 -0.01737454  0.03422275 -0.03988345\n",
      "  -0.03696836 -0.00116388 -0.03890417 -0.01269937  0.00507911  0.02982992\n",
      "   0.00697022 -0.04665654 -0.02918237 -0.02491035  0.02996481  0.00297766\n",
      "   0.03417213 -0.02279012 -0.01034534  0.02630845 -0.03460188  0.00932224\n",
      "  -0.04352104 -0.02126801  0.03686359 -0.02912866 -0.01059956  0.00259133\n",
      "   0.00324165 -0.04615122 -0.04699592 -0.02463116 -0.00887086 -0.04108449\n",
      "  -0.01765037 -0.03592086 -0.02967109  0.00558911 -0.00881178 -0.0483201\n",
      "  -0.00987961  0.02456332  0.00283928 -0.01529993  0.01785861 -0.01242632]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of embeddings : \",embeddings.shape)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings :  (3, 12, 8)\n",
      "[[[ 0.03011117 -0.02670218 -0.00847875  0.034897   -0.01051865\n",
      "   -0.02711916 -0.02487536 -0.02674422]\n",
      "  [-0.00881178 -0.0483201  -0.00987961  0.02456332  0.00283928\n",
      "   -0.01529993  0.01785861 -0.01242632]\n",
      "  [-0.03739148 -0.02144562  0.04590155 -0.02630723 -0.0317054\n",
      "   -0.04067265 -0.02565771  0.0188408 ]\n",
      "  [ 0.01338479  0.01484675 -0.00882455 -0.00779973  0.0283351\n",
      "   -0.04327079  0.02083454 -0.04233762]\n",
      "  [-0.03554603  0.04314442 -0.03227742 -0.0430434  -0.01460426\n",
      "   -0.03224637 -0.02712467 -0.03528814]\n",
      "  [-0.04699592 -0.02463116 -0.00887086 -0.04108449 -0.01765037\n",
      "   -0.03592086 -0.02967109  0.00558911]\n",
      "  [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874\n",
      "    0.03153331 -0.00326921 -0.01445078]\n",
      "  [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874\n",
      "    0.03153331 -0.00326921 -0.01445078]\n",
      "  [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874\n",
      "    0.03153331 -0.00326921 -0.01445078]\n",
      "  [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874\n",
      "    0.03153331 -0.00326921 -0.01445078]\n",
      "  [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874\n",
      "    0.03153331 -0.00326921 -0.01445078]\n",
      "  [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874\n",
      "    0.03153331 -0.00326921 -0.01445078]]\n",
      "\n",
      " [[ 0.04607674 -0.00758297 -0.03569062  0.01863006 -0.04490864\n",
      "   -0.04510683  0.01303491  0.02913488]\n",
      "  [ 0.02996481  0.00297766  0.03417213 -0.02279012 -0.01034534\n",
      "    0.02630845 -0.03460188  0.00932224]\n",
      "  [-0.01300643  0.01481131 -0.03093816  0.00416549 -0.04258502\n",
      "    0.03763345 -0.03530914  0.00040434]\n",
      "  [-0.03554603  0.04314442 -0.03227742 -0.0430434  -0.01460426\n",
      "   -0.03224637 -0.02712467 -0.03528814]\n",
      "  [-0.04699592 -0.02463116 -0.00887086 -0.04108449 -0.01765037\n",
      "   -0.03592086 -0.02967109  0.00558911]\n",
      "  [-0.0336052   0.04775343 -0.04578439  0.0457306   0.00208535\n",
      "   -0.04167062 -0.02230759  0.04546758]\n",
      "  [-0.03739148 -0.02144562  0.04590155 -0.02630723 -0.0317054\n",
      "   -0.04067265 -0.02565771  0.0188408 ]\n",
      "  [-0.01300643  0.01481131 -0.03093816  0.00416549 -0.04258502\n",
      "    0.03763345 -0.03530914  0.00040434]\n",
      "  [-0.04352104 -0.02126801  0.03686359 -0.02912866 -0.01059956\n",
      "    0.00259133  0.00324165 -0.04615122]\n",
      "  [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874\n",
      "    0.03153331 -0.00326921 -0.01445078]\n",
      "  [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874\n",
      "    0.03153331 -0.00326921 -0.01445078]\n",
      "  [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874\n",
      "    0.03153331 -0.00326921 -0.01445078]]\n",
      "\n",
      " [[-0.04767499  0.01561514  0.00049329  0.02191934 -0.03796053\n",
      "    0.04406155  0.03259062 -0.04780463]\n",
      "  [-0.01540776  0.02702776  0.02418702 -0.0087474   0.00180035\n",
      "    0.01054322 -0.0187981   0.01683738]\n",
      "  [-0.00881178 -0.0483201  -0.00987961  0.02456332  0.00283928\n",
      "   -0.01529993  0.01785861 -0.01242632]\n",
      "  [ 0.01338479  0.01484675 -0.00882455 -0.00779973  0.0283351\n",
      "   -0.04327079  0.02083454 -0.04233762]\n",
      "  [-0.00881178 -0.0483201  -0.00987961  0.02456332  0.00283928\n",
      "   -0.01529993  0.01785861 -0.01242632]\n",
      "  [-0.04699592 -0.02463116 -0.00887086 -0.04108449 -0.01765037\n",
      "   -0.03592086 -0.02967109  0.00558911]\n",
      "  [ 0.04813459 -0.00118749  0.04338625 -0.01737454  0.03422275\n",
      "   -0.03988345 -0.03696836 -0.00116388]\n",
      "  [-0.03890417 -0.01269937  0.00507911  0.02982992  0.00697022\n",
      "   -0.04665654 -0.02918237 -0.02491035]\n",
      "  [ 0.02996481  0.00297766  0.03417213 -0.02279012 -0.01034534\n",
      "    0.02630845 -0.03460188  0.00932224]\n",
      "  [-0.04352104 -0.02126801  0.03686359 -0.02912866 -0.01059956\n",
      "    0.00259133  0.00324165 -0.04615122]\n",
      "  [-0.04699592 -0.02463116 -0.00887086 -0.04108449 -0.01765037\n",
      "   -0.03592086 -0.02967109  0.00558911]\n",
      "  [-0.00881178 -0.0483201  -0.00987961  0.02456332  0.00283928\n",
      "   -0.01529993  0.01785861 -0.01242632]]]\n"
     ]
    }
   ],
   "source": [
    "embeddings=embeddings.reshape(-1,maxlen,8)\n",
    "print(\"Shape of embeddings : \",embeddings.shape)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoding for  1 th word in 1 th document is : \n",
      "\n",
      " [ 0.03011117 -0.02670218 -0.00847875  0.034897   -0.01051865 -0.02711916\n",
      " -0.02487536 -0.02674422]\n",
      "The encoding for  2 th word in 1 th document is : \n",
      "\n",
      " [-0.00881178 -0.0483201  -0.00987961  0.02456332  0.00283928 -0.01529993\n",
      "  0.01785861 -0.01242632]\n",
      "The encoding for  3 th word in 1 th document is : \n",
      "\n",
      " [-0.03739148 -0.02144562  0.04590155 -0.02630723 -0.0317054  -0.04067265\n",
      " -0.02565771  0.0188408 ]\n",
      "The encoding for  4 th word in 1 th document is : \n",
      "\n",
      " [ 0.01338479  0.01484675 -0.00882455 -0.00779973  0.0283351  -0.04327079\n",
      "  0.02083454 -0.04233762]\n",
      "The encoding for  5 th word in 1 th document is : \n",
      "\n",
      " [-0.03554603  0.04314442 -0.03227742 -0.0430434  -0.01460426 -0.03224637\n",
      " -0.02712467 -0.03528814]\n",
      "The encoding for  6 th word in 1 th document is : \n",
      "\n",
      " [-0.04699592 -0.02463116 -0.00887086 -0.04108449 -0.01765037 -0.03592086\n",
      " -0.02967109  0.00558911]\n",
      "The encoding for  7 th word in 1 th document is : \n",
      "\n",
      " [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874  0.03153331\n",
      " -0.00326921 -0.01445078]\n",
      "The encoding for  8 th word in 1 th document is : \n",
      "\n",
      " [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874  0.03153331\n",
      " -0.00326921 -0.01445078]\n",
      "The encoding for  9 th word in 1 th document is : \n",
      "\n",
      " [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874  0.03153331\n",
      " -0.00326921 -0.01445078]\n",
      "The encoding for  10 th word in 1 th document is : \n",
      "\n",
      " [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874  0.03153331\n",
      " -0.00326921 -0.01445078]\n",
      "The encoding for  11 th word in 1 th document is : \n",
      "\n",
      " [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874  0.03153331\n",
      " -0.00326921 -0.01445078]\n",
      "The encoding for  12 th word in 1 th document is : \n",
      "\n",
      " [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874  0.03153331\n",
      " -0.00326921 -0.01445078]\n",
      "The encoding for  1 th word in 2 th document is : \n",
      "\n",
      " [ 0.04607674 -0.00758297 -0.03569062  0.01863006 -0.04490864 -0.04510683\n",
      "  0.01303491  0.02913488]\n",
      "The encoding for  2 th word in 2 th document is : \n",
      "\n",
      " [ 0.02996481  0.00297766  0.03417213 -0.02279012 -0.01034534  0.02630845\n",
      " -0.03460188  0.00932224]\n",
      "The encoding for  3 th word in 2 th document is : \n",
      "\n",
      " [-0.01300643  0.01481131 -0.03093816  0.00416549 -0.04258502  0.03763345\n",
      " -0.03530914  0.00040434]\n",
      "The encoding for  4 th word in 2 th document is : \n",
      "\n",
      " [-0.03554603  0.04314442 -0.03227742 -0.0430434  -0.01460426 -0.03224637\n",
      " -0.02712467 -0.03528814]\n",
      "The encoding for  5 th word in 2 th document is : \n",
      "\n",
      " [-0.04699592 -0.02463116 -0.00887086 -0.04108449 -0.01765037 -0.03592086\n",
      " -0.02967109  0.00558911]\n",
      "The encoding for  6 th word in 2 th document is : \n",
      "\n",
      " [-0.0336052   0.04775343 -0.04578439  0.0457306   0.00208535 -0.04167062\n",
      " -0.02230759  0.04546758]\n",
      "The encoding for  7 th word in 2 th document is : \n",
      "\n",
      " [-0.03739148 -0.02144562  0.04590155 -0.02630723 -0.0317054  -0.04067265\n",
      " -0.02565771  0.0188408 ]\n",
      "The encoding for  8 th word in 2 th document is : \n",
      "\n",
      " [-0.01300643  0.01481131 -0.03093816  0.00416549 -0.04258502  0.03763345\n",
      " -0.03530914  0.00040434]\n",
      "The encoding for  9 th word in 2 th document is : \n",
      "\n",
      " [-0.04352104 -0.02126801  0.03686359 -0.02912866 -0.01059956  0.00259133\n",
      "  0.00324165 -0.04615122]\n",
      "The encoding for  10 th word in 2 th document is : \n",
      "\n",
      " [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874  0.03153331\n",
      " -0.00326921 -0.01445078]\n",
      "The encoding for  11 th word in 2 th document is : \n",
      "\n",
      " [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874  0.03153331\n",
      " -0.00326921 -0.01445078]\n",
      "The encoding for  12 th word in 2 th document is : \n",
      "\n",
      " [-0.0462851   0.00482037 -0.01747657 -0.00098497  0.03795874  0.03153331\n",
      " -0.00326921 -0.01445078]\n",
      "The encoding for  1 th word in 3 th document is : \n",
      "\n",
      " [-0.04767499  0.01561514  0.00049329  0.02191934 -0.03796053  0.04406155\n",
      "  0.03259062 -0.04780463]\n",
      "The encoding for  2 th word in 3 th document is : \n",
      "\n",
      " [-0.01540776  0.02702776  0.02418702 -0.0087474   0.00180035  0.01054322\n",
      " -0.0187981   0.01683738]\n",
      "The encoding for  3 th word in 3 th document is : \n",
      "\n",
      " [-0.00881178 -0.0483201  -0.00987961  0.02456332  0.00283928 -0.01529993\n",
      "  0.01785861 -0.01242632]\n",
      "The encoding for  4 th word in 3 th document is : \n",
      "\n",
      " [ 0.01338479  0.01484675 -0.00882455 -0.00779973  0.0283351  -0.04327079\n",
      "  0.02083454 -0.04233762]\n",
      "The encoding for  5 th word in 3 th document is : \n",
      "\n",
      " [-0.00881178 -0.0483201  -0.00987961  0.02456332  0.00283928 -0.01529993\n",
      "  0.01785861 -0.01242632]\n",
      "The encoding for  6 th word in 3 th document is : \n",
      "\n",
      " [-0.04699592 -0.02463116 -0.00887086 -0.04108449 -0.01765037 -0.03592086\n",
      " -0.02967109  0.00558911]\n",
      "The encoding for  7 th word in 3 th document is : \n",
      "\n",
      " [ 0.04813459 -0.00118749  0.04338625 -0.01737454  0.03422275 -0.03988345\n",
      " -0.03696836 -0.00116388]\n",
      "The encoding for  8 th word in 3 th document is : \n",
      "\n",
      " [-0.03890417 -0.01269937  0.00507911  0.02982992  0.00697022 -0.04665654\n",
      " -0.02918237 -0.02491035]\n",
      "The encoding for  9 th word in 3 th document is : \n",
      "\n",
      " [ 0.02996481  0.00297766  0.03417213 -0.02279012 -0.01034534  0.02630845\n",
      " -0.03460188  0.00932224]\n",
      "The encoding for  10 th word in 3 th document is : \n",
      "\n",
      " [-0.04352104 -0.02126801  0.03686359 -0.02912866 -0.01059956  0.00259133\n",
      "  0.00324165 -0.04615122]\n",
      "The encoding for  11 th word in 3 th document is : \n",
      "\n",
      " [-0.04699592 -0.02463116 -0.00887086 -0.04108449 -0.01765037 -0.03592086\n",
      " -0.02967109  0.00558911]\n",
      "The encoding for  12 th word in 3 th document is : \n",
      "\n",
      " [-0.00881178 -0.0483201  -0.00987961  0.02456332  0.00283928 -0.01529993\n",
      "  0.01785861 -0.01242632]\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(embeddings):\n",
    "    for j,word in enumerate(doc):\n",
    "        print(\"The encoding for \",j+1,\"th word\",\"in\",i+1,\"th document is : \\n\\n\",word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
